{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "delete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "paVKkPMgLv8k"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ufal.udpipe\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "xbGeOB2fMBry"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from tqdm import tqdm\n",
        "from ufal.udpipe import Model, Pipeline"
      ],
      "metadata": {
        "id": "xHCHsxVAMLHI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://rusvectores.org/static/models/udpipe_syntagrus.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRAxZtxScoxP",
        "outputId": "cf364124-a547-4a06-f5a2-d9507a838119"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 12:27:49--  https://rusvectores.org/static/models/udpipe_syntagrus.model\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40616122 (39M)\n",
            "Saving to: ‘udpipe_syntagrus.model’\n",
            "\n",
            "udpipe_syntagrus.mo 100%[===================>]  38.73M   157MB/s    in 0.2s    \n",
            "\n",
            "2022-03-21 12:27:50 (157 MB/s) - ‘udpipe_syntagrus.model’ saved [40616122/40616122]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_udpipe = Model.load(\"udpipe_syntagrus.model\")\n",
        "pipeline = Pipeline(\n",
        "    model_udpipe, \"tokenize\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\"\n",
        "    )"
      ],
      "metadata": {
        "id": "PV7GWo5Mct06"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vyhuholl/russian_detoxification/master/data/test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRYKcBfTMVeN",
        "outputId": "8ead370e-f52e-436e-c520-4ebe46fbff43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 12:29:45--  https://raw.githubusercontent.com/vyhuholl/russian_detoxification/master/data/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1941971 (1.9M) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>]   1.85M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-03-21 12:29:46 (71.0 MB/s) - ‘test.txt’ saved [1941971/1941971]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vyhuholl/russian_detoxification/master/data/toxic_vocab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVwM83esMeIC",
        "outputId": "ed0d602b-35d1-4dc5-e0d6-909580a4b926"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 12:29:48--  https://raw.githubusercontent.com/vyhuholl/russian_detoxification/master/data/toxic_vocab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7618338 (7.3M) [text/plain]\n",
            "Saving to: ‘toxic_vocab.txt’\n",
            "\n",
            "toxic_vocab.txt     100%[===================>]   7.26M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-03-21 12:29:49 (139 MB/s) - ‘toxic_vocab.txt’ saved [7618338/7618338]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(\n",
        "    text: str, pipeline: Pipeline, tags: bool = False, lemmas: bool = False\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Tokenizes a text with the UDPipe pipeline.\n",
        "\n",
        "    Parameters:\n",
        "        inputs_path: str\n",
        "        preds_path: str\n",
        "        results_file: str\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    processed = pipeline.process(text)\n",
        "    content = [\n",
        "        line for line in processed.split(\"\\n\") if not line.startswith(\"#\")\n",
        "    ]\n",
        "    tagged = [w.split(\"\\t\") for w in content if w]\n",
        "    tokens = []\n",
        "\n",
        "    for token in tagged:\n",
        "        if token[3] == \"PUNCT\":\n",
        "            continue\n",
        "        token_res = \"\"\n",
        "        if lemmas:\n",
        "            token_res = token[2]\n",
        "        else:\n",
        "            token_res = token[1]\n",
        "        if tags:\n",
        "            token_res += \"_\" + token[3]\n",
        "        tokens.append(token_res)\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "3cyOEaSCdhA-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test.txt\") as inputs_file:\n",
        "    texts = inputs_file.readlines()\n",
        "\n",
        "with open(\"toxic_vocab.txt\") as vocab_file:\n",
        "    vocab = [line.strip() for line in vocab_file.readlines()]"
      ],
      "metadata": {
        "id": "UCPp7d7_dp_z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for text in tqdm(texts, desc=\"Deleting toxic words...\"):\n",
        "    words = tokenize(text, pipeline, lemmas=False)\n",
        "    lemmas = tokenize(text, pipeline, lemmas=True)\n",
        "    clean_text = \" \".join(\n",
        "        [word for word, lemma in zip(words, lemmas) if lemma not in vocab]\n",
        "        )\n",
        "    results.append(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V_pI6pseC9k",
        "outputId": "777b1cc9-2467-4807-e057-fb170d7fc2a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deleting toxic words...: 100%|██████████| 12358/12358 [17:29<00:00, 11.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"preds_delete.txt\", \"w\") as results_file:\n",
        "    for text in results:\n",
        "        results_file.write(text + \"\\n\")"
      ],
      "metadata": {
        "id": "xlHZDyonfnMC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDhGGMNZOTJZ",
        "outputId": "d04420f1-cfd2-4974-f6d3-a355a53a4a9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "вот это точьно пидорасы\n",
            "скальпы местного населения за деньги не принимали, не резали руки детям за отказ их родителей работать и невыполнение плана, Какой потрясающе удобный подход. А еще не набивали соломой трупы врагов и не насиловали предметы домашнего обихода туземцев. Что не добавили и эти два пункта? Я привел тебе факты многочисленных убийств аборигенов ради захвата их земель или подчинения их народов, а ты ловко выкручиваешься тем, что вырезали-то не всех поголовно, а всего лишь непокорные аулы, концлагери строили не для конкретных народов, а всех подряд, да и резервации не строили - ведь просто выкинуть из поезда в сухую степь Средней Азии полмиллиона насильно депортированных из родных краев вайнахов и сколько-то там других народов было гораздо проще, чем что-то для них еще и строить. Войны были есть и будут Это была экспансия, а не война. Разницу чуешь, или мне снова разжевать? Так что нехер пытаться обелить то, что было. Не сразу заметил, что ты еще и автор этого поста, где жалуешься на мертвое образование и при этом сам с околонулевой осведомленностью в истории пытаешься с кем-то еще спорить.\n",
            "вы лохи ебучие,пешком научитесь ходить,какие нахуй привода у уазе, чайники ебаные\n",
            "судить это мягко растрелять как предателя родины и народа\n",
            "вот ты охуевшая\n",
            "а здесь всё еще продолжается обсуждение спектакля с ефремовым? да уж, подставили мужика конкретно. еще и хватает долбоёбов смеяться над этим.\n",
            "Ладно, уговорили. Вандалы это, хорошо. Пусть это вандалы, хулиганы, отморозки, кактамеще. Только... вопрос остается: Можно быстрее?\n",
            "уничтожать всю госдуму, чтоб зараза не распространялась дальше\n",
            "так пидоров и на зывают дурами 🤣\n",
            "сука,они обижают собачку,твари,горите в аду!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head preds_delete.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8qaEqfiOWdy",
        "outputId": "ee462946-9200-4398-d477-70ebce9694fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "вот это точьно\n",
            "скальпы местного населения за деньги не принимали не резали руки детям за отказ их родителей работать и невыполнение плана Какой потрясающе удобный подход А еще не набивали соломой трупы врагов и не насиловали предметы домашнего обихода туземцев Что не добавили и эти два пункта Я привел тебе факты многочисленных убийств аборигенов ради захвата их земель или подчинения их народов а ты ловко выкручиваешься тем что вырезали-то не всех поголовно а всего лишь непокорные аулы концлагери строили не для конкретных народов а всех подряд да и резервации не строили ведь просто выкинуть из поезда в сухую степь Средней Азии полмиллиона насильно депортированных из родных краев вайнахов и сколько-то там других народов было гораздо проще чем что-то для них еще и строить Войны были есть и будут Это была экспансия а не война Разницу чуешь или мне снова разжевать Так что нехер пытаться обелить то что было Не сразу заметил что ты еще и автор этого поста где жалуешься на мертвое образование и при этом сам с околонулевой осведомленностью в истории пытаешься с кем-то еще спорить\n",
            "вы лохи пешком научитесь ходить ,какие привода у уазе чайники\n",
            "судить это мягко растрелять как предателя родины и народа\n",
            "вот ты\n",
            "а здесь всё еще продолжается обсуждение спектакля с ефремовым да уж подставили мужика конкретно. еще и хватает смеяться над этим\n",
            "Ладно уговорили Вандалы это хорошо Пусть это вандалы хулиганы отморозки кактамеще Только вопрос остается Можно быстрее\n",
            "уничтожать всю госдуму чтоб зараза не распространялась дальше\n",
            "так и на зывают 🤣\n",
            "сука,они обижают собачку,твари горите в аду\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"preds_delete.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fTm6UOpVTTLB",
        "outputId": "37bf97bc-71e8-45a6-ad34-41f170fdb692"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b96a421-95f4-48a0-8022-d26dc819cffa\", \"preds_delete.txt\", 1775173)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sVp_R_5kUjPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
